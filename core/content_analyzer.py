"""
vidgen content analyzer module

analyzes pdf content and creates structured video segments.
uses openai to intelligently break content into digestible video sections
and matches images to appropriate segments.
"""

import json
import os
from typing import List, Dict, Optional
from openai import OpenAI
import re
from jinja2 import Environment, FileSystemLoader, select_autoescape
from pathlib import Path
from core.logger import get_logger

logger = get_logger(__name__)


class ContentAnalyzer:
    """analyze and structure pdf content for video creation."""
    
    def __init__(self, api_key: Optional[str] = None, target_segments: int = 7, 
                 segment_duration: int = 45):
        """
        initialize content analyzer.
        args:
            api_key: openai api key
            target_segments: target number of video segments
            segment_duration: target duration per segment in seconds
        """
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("openai api key required. please set OPENAI_API_KEY in .env")
        
        # initialize openai client
        self.client = OpenAI(api_key=self.api_key)
        # set target segments and segment duration
        self.target_segments = target_segments
        self.segment_duration = segment_duration
        # set openai model
        self.model = "gpt-4o"
        
        # initialize jinja2 environment for prompt templates
        prompts_dir = Path(__file__).parent.parent / 'prompts'
        self.jinja_env = Environment(
            loader=FileSystemLoader(str(prompts_dir)),
            autoescape=select_autoescape(['html', 'xml'])
        )
    
    def analyze_content(self, pdf_content: Dict, images_metadata: Optional[List[Dict]] = None) -> Dict:
        """analyze pdf content and create video segments."""
        logger.info("starting content analysis")
        
        # create video outline
        outline = self._create_video_outline(pdf_content)
        
        # match images to segments
        if images_metadata:
            outline = self._match_images_to_segments(outline, images_metadata)
        
        # step 3: identify stock image keywords
        outline = self._identify_stock_keywords(outline)
        
        logger.info(f"created {len(outline['segments'])} video segments")
        
        return outline

    def _generate_summary(self, prompt: str) -> str:
        """
        utility method to generate summary/outline using openai API.
        Args:
            prompt: the prompt string to send to the model.
        returns:
            the text response generated by openai.
        throws:
            exception on openai API error.
        """
        # load system prompt from template
        system_template = self.jinja_env.get_template('outline_system.j2')
        system_prompt = system_template.render()
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.7,
            max_tokens=2000
        )
        return response.choices[0].message.content
    
    def _create_video_outline(self, pdf_content: Dict) -> Dict:
        """create structured video outline from pdf content."""
        logger.info("creating video outline with ai model")
        
        # prepare content summary for ai model
        # TODO: passing the whole pdf may cause the context window to be too large, we need to think of a way to intelligently split the content
        sections_summary = []
        for section in pdf_content.get('sections', []):
            sections_summary.append({
                'title': section['title'],
                'content_preview': section['content'][:500]
            })
        
        # create outline prompt
        prompt = self._create_outline_prompt(
            pdf_content.get('title', 'Untitled'),
            sections_summary,
            self.target_segments,
            self.segment_duration
        )
        
        try:
            outline_text = self._generate_summary(prompt)
            outline = self._parse_outline(outline_text, pdf_content)
            
            logger.info("successfully created video outline")
            return outline
            
        except Exception as e:
            logger.error(f"error creating outline: {str(e)}")
            # fallback: create simple outline from sections
            return self._create_fallback_outline(pdf_content)
    
    def _create_outline_prompt(self, title: str, sections: List[Dict], 
                               target_segments: int, duration: int) -> str:
        """create prompt for video outline generation.
        args:
            title: title of the document
            sections: list of sections
            target_segments: target number of video segments
            duration: target duration per segment in seconds
        returns:
            prompt for video outline generation
        """
        
        sections_text = "\n\n".join([
            f"Section: {s['title']}\n{s['content_preview']}"
            for s in sections[:10]  # limit to first 10 sections to avoid context window issues
        ])
        
        # load and render template
        template = self.jinja_env.get_template('outline_prompt.j2')
        prompt = template.render(
            title=title,
            target_segments=target_segments,
            duration=duration,
            sections_text=sections_text
        )
        
        return prompt
    
    def _parse_outline(self, outline_text: str, pdf_content: Dict) -> Dict:
        """
        parse ai-generated outline into structured format.
        args:
            outline_text: raw outline from ai
            pdf_content: original pdf content
        returns:
            structured outline dictionary
        """
        segments = []
        current_segment = None
        
        lines = outline_text.split('\n')
        
        for line in lines:
            line = line.strip()
            
            # Check for segment start
            if re.match(r'^SEGMENT \d+:', line):
                if current_segment:
                    segments.append(current_segment)
                
                title = re.sub(r'^SEGMENT \d+:\s*', '', line)
                current_segment = {
                    'title': title,
                    'purpose': '',
                    'key_points': [],
                    'visual_keywords': [],
                    'duration': self.segment_duration,
                    'pdf_images': [],
                    'stock_image_query': None,
                    'content': ''
                }
            
            elif current_segment:
                if line.startswith('PURPOSE:'):
                    current_segment['purpose'] = line.replace('PURPOSE:', '').strip()
                
                elif line.startswith('- ') and 'KEY_POINTS' in outline_text[max(0, outline_text.find(line)-50):outline_text.find(line)]:
                    current_segment['key_points'].append(line[2:].strip())
                
                elif line.startswith('VISUAL_KEYWORDS:'):
                    keywords_str = line.replace('VISUAL_KEYWORDS:', '').strip()
                    current_segment['visual_keywords'] = [k.strip() for k in keywords_str.split(',')]
                
                elif line.startswith('DURATION:'):
                    try:
                        duration_str = re.search(r'\d+', line)
                        if duration_str:
                            current_segment['duration'] = int(duration_str.group())
                    except:
                        pass
        
        # add last segment
        if current_segment:
            segments.append(current_segment)
        
        # if parsing failed or got too few segments, use fallback
        if len(segments) < 3:
            logger.warning("outline parsing resulted in too few segments, using fallback")
            return self._create_fallback_outline(pdf_content)
        
        return {
            'title': pdf_content.get('title', 'Untitled'),
            'total_segments': len(segments),
            'estimated_duration': sum(s['duration'] for s in segments),
            'segments': segments
        }
    
    def _create_fallback_outline(self, pdf_content: Dict) -> Dict:
        """
        create simple outline directly from pdf sections.
        args:
            pdf_content: pdf content dictionary
        returns:
            basic outline
        """
        logger.info("creating fallback outline from pdf sections")
        
        sections = pdf_content.get('sections', [])
        segments = []
        
        # Introduction
        segments.append({
            'title': 'Introduction',
            'purpose': f"Introduce {pdf_content.get('title', 'the topic')}",
            'key_points': ['Overview of main topics', 'Why this matters'],
            'visual_keywords': ['introduction', 'overview', pdf_content.get('title', 'topic')],
            'duration': self.segment_duration,
            'pdf_images': [],
            'stock_image_query': None,
            'content': sections[0]['content'][:300] if sections else ''
        })
        
        # main sections
        for i, section in enumerate(sections[:self.target_segments-2], 1):
            segment = {
                'title': section['title'],
                'purpose': f"Explain {section['title']}",
                'key_points': self._extract_key_points(section['content']),
                'visual_keywords': self._extract_keywords(section['title']),
                'duration': self.segment_duration,
                'pdf_images': [],
                'stock_image_query': None,
                'content': section['content'][:500]
            }
            segments.append(segment)
        
        # conclusion
        segments.append({
            'title': 'Summary',
            'purpose': 'Recap key takeaways',
            'key_points': ['Review main concepts', 'Next steps'],
            'visual_keywords': ['summary', 'conclusion', 'takeaways'],
            'duration': self.segment_duration,
            'pdf_images': [],
            'stock_image_query': None,
            'content': ''
        })
        
        return {
            'title': pdf_content.get('title', 'Untitled'),
            'total_segments': len(segments),
            'estimated_duration': len(segments) * self.segment_duration,
            'segments': segments
        }
    
    def _extract_key_points(self, content: str, max_points: int = 3) -> List[str]:
        """extract key points from content text."""
        # simple extraction: split by newlines and take first few non-empty lines
        lines = [line.strip() for line in content.split('\n') if line.strip()]
        return lines[:max_points]
    
    def _extract_keywords(self, text: str) -> List[str]:
        """extract keywords from text."""
        # simple keyword extraction
        words = re.findall(r'\b[A-Z][a-z]+\b', text)
        return words[:5]
    
    def _match_images_to_segments(self, outline: Dict, images_metadata: List[Dict]) -> Dict:
        """
        match pdf images to appropriate video segments.
        args:
            outline: video outline
            images_metadata: list of labeled images
        returns:
            updated outline with matched images
        """
        logger.info("matching images to segments")
        
        for segment in outline['segments']:
            # match images based on keywords and labels
            matched_images = []
            
            segment_keywords = set([
                segment['title'].lower(),
                segment.get('purpose', '').lower()
            ] + [kw.lower() for kw in segment.get('visual_keywords', [])])
            
            for img in images_metadata:
                # calculate relevance score
                score = 0
                img_label = img.get('label', '').lower()
                img_desc = img.get('description', '').lower()
                img_elements = ' '.join(img.get('key_elements', [])).lower()
                
                for keyword in segment_keywords:
                    if keyword in img_label:
                        score += 3
                    if keyword in img_desc:
                        score += 2
                    if keyword in img_elements:
                        score += 1
                
                if score > 0:
                    matched_images.append({
                        'image': img,
                        'relevance_score': score
                    })
            
            # sort by relevance and take top matches
            matched_images.sort(key=lambda x: x['relevance_score'], reverse=True)
            segment['pdf_images'] = [m['image'] for m in matched_images[:2]]  # Max 2 images per segment
            
            if segment['pdf_images']:
                logger.info(f"matched {len(segment['pdf_images'])} images to segment: {segment['title']}")
        
        return outline
    
    def _identify_stock_keywords(self, outline: Dict) -> Dict:
        """
        identify best stock image search keywords for each segment.
        args:
            outline: video outline
        returns:
            updated outline with stock image queries
        """
        for segment in outline['segments']:
            # if segment has pdf images, might not need stock images
            if len(segment.get('pdf_images', [])) >= 2:
                continue
            
            # use visual keywords to create stock image query
            keywords = segment.get('visual_keywords', [])
            if keywords:
                # take first 2-3 keywords for search
                query = ' '.join(keywords[:3])
                segment['stock_image_query'] = query
                logger.debug(f"stock image query for '{segment['title']}': {query}")
        
        return outline
    
    def save_outline(self, outline: Dict, output_path: str):
        """
        save outline to json file.
        args:
            outline: video outline
            output_path: path to save json
        """
        with open(output_path, 'w') as f:
            json.dump(outline, f, indent=2)
        
        logger.info(f"saved outline to {output_path}")


def analyze_pdf_content(pdf_content: Dict, images_metadata: Optional[List[Dict]] = None,
                       api_key: Optional[str] = None) -> Dict:
    """
    convenience function to analyze pdf content.
    args:
        pdf_content: structured pdf content
        images_metadata: labeled images
        api_key: openai api key (optional)
    returns:
        video outline
    """
    analyzer = ContentAnalyzer(api_key)
    return analyzer.analyze_content(pdf_content, images_metadata)


if __name__ == "__main__":
    # test vidgen content analyzer
    import sys
    
    if len(sys.argv) < 2:
        print("usage: python content_analyzer.py <pdf_content.json> [images_metadata.json]")
        sys.exit(1)
    
    content_path = sys.argv[1]
    images_path = sys.argv[2] if len(sys.argv) > 2 else None
    
    print("**** loading content ****")
    with open(content_path, 'r') as f:
        pdf_content = json.load(f)
    
    images_metadata = None
    if images_path and os.path.exists(images_path):
        with open(images_path, 'r') as f:
            images_metadata = json.load(f)
        print(f"loaded {len(images_metadata)} images")
    
    print("**** analyzing content ****")
    analyzer = ContentAnalyzer()
    outline = analyzer.analyze_content(pdf_content, images_metadata)
    
    print(f"**** video outline created ****")
    print(f"title: {outline['title']}")
    print(f"total segments: {outline['total_segments']}")
    print(f"estimated duration: {outline['estimated_duration']} seconds ({outline['estimated_duration']//60} minutes)\n")
    
    for i, segment in enumerate(outline['segments'], 1):
        print(f"**** segment {i}: {segment['title']} ****")
        print(f"purpose: {segment['purpose']}")
        print(f"duration: {segment['duration']}s")
        print(f"key points: {len(segment['key_points'])}")
        for point in segment['key_points']:
            print(f"  - {point}")
        print(f"visual keywords: {', '.join(segment['visual_keywords'])}")
        print(f"pdf images: {len(segment.get('pdf_images', []))}")
        if segment.get('stock_image_query'):
            print(f"stock image query: {segment['stock_image_query']}")
    
    # save outline
    output_path = "temp/video_outline.json"
    analyzer.save_outline(outline, output_path)
    print(f"**** outline saved to {output_path} ****")

